{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29a516d2-f1ac-4f4b-ac0e-2230fab6d91a",
   "metadata": {},
   "source": [
    "# Multi-Year Zonal Mode Aggregation for Crop Data Layers\n",
    "\n",
    "Author: Shuo Yu\n",
    "\n",
    "Date: 2022/08\n",
    "\n",
    "---\n",
    "\n",
    "## Description\n",
    "This script computes zonal statistics (mode values) for raster crop classification layers (CDL) over multiple years using field boundary polygons (CLU shapefile).\n",
    "\n",
    "---\n",
    "\n",
    "## Workflow\n",
    "1. Load shapefile of field boundaries (with unique ID).  \n",
    "2. Load matching CSV with the same IDs for later merging.  \n",
    "3. For each CDL raster (per year):  \n",
    "   - Reproject field boundaries to match raster CRS.  \n",
    "   - Calculate the mode of CDL categories within each polygon.  \n",
    "   - Append the result as a new column (e.g., `CDL2013`).  \n",
    "4. Merge all results back with the input CSV on `ID`.  \n",
    "5. Save final merged dataset to CSV.  \n",
    "\n",
    "---\n",
    "\n",
    "## Notes\n",
    "- CRS must match between raster and vector. Here we use **EPSG:26915**.  \n",
    "- CDL background values (`0`) are treated as nodata and ignored.  \n",
    "- The mode is computed using categorical zonal counts.  \n",
    "- This version avoids per-geometry loops for efficiency.  \n",
    "\n",
    "---\n",
    "\n",
    "## Output\n",
    "- DataFrame with original CSV columns plus CDL values for each year.  \n",
    "- Shapefile of merged DataFrame.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a4d411-e7d3-4e89-a2a0-cce39690b0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['USE_PYGEOS'] = '0'\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import osgeo\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import MultiLineString, LineString, Point, MultiPolygon, Polygon, MultiPoint\n",
    "from shapely.ops import split, substring\n",
    "from rasterio import features\n",
    "import rasterio\n",
    "import rasterio.transform\n",
    "import rasterio.mask\n",
    "import rasterio.warp\n",
    "import rasterio.windows\n",
    "from rasterio.transform import from_origin\n",
    "from rasterio.features import rasterize\n",
    "from shapely.geometry import shape\n",
    "import fiona\n",
    "from pyproj import CRS, Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6db7255-2b22-4cb8-aa6f-dbf9ff92863c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "threshold_acreage = 1\n",
    "neg_buffer = 30\n",
    "cwd = os.getcwd()\n",
    "state_abb = 'IL'\n",
    "state_name = 'Illinois'\n",
    "state_fips = '26'\n",
    "CLU_directory = r'D:\\CLU\\mi'\n",
    "CSB1623_address = r'D:\\School\\Research\\CoverCropDetection\\Data_Original\\NationalCSB_2016-2023_rev23\\CSB1623.gdb'\n",
    "CSB1320_address = r'D:\\School\\Research\\CoverCropDetection\\Data_Original\\2020_National_CSB_gdb\\National_Final_gdb\\CSB1320.gdb'\n",
    "# Shapefiles of NationalCSB\n",
    "# Path to the .gdb file\n",
    "gdb_path = CSB1623_address\n",
    "county_shapefile_address = r'E:\\CoverCrop\\Data_Original\\cb_2018_us_county_20m.zip'\n",
    "output_dir = os.path.join(cwd, rf'Data_cleaned\\CLU_{state_abb}')\n",
    "# Create the directory, existing = ok\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90cba6e-737d-411d-87bb-be6776e60b9a",
   "metadata": {},
   "source": [
    "### 1. Read in CSB data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca6e808-d622-47a5-a4c7-795f2dbea1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated dictionary for mapping STATEFP to state names\n",
    "statefp_to_state_name = {\n",
    "    '17': 'Illinois',\n",
    "    '18': 'Indiana',\n",
    "    '19': 'Iowa',\n",
    "    '26': 'Michigan',\n",
    "    '27': 'Minnesota',\n",
    "    '31': 'Nebraska',\n",
    "    '39': 'Ohio',\n",
    "    '46': 'South Dakota',\n",
    "    '55': 'Wisconsin',\n",
    "    '29': 'Missouri',\n",
    "    '05': 'Arkansas'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402de598-edfc-4778-aa23-8fc9175c2272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the shapefile into a GeoDataFrame\n",
    "counties = gpd.read_file(county_shapefile_address)\n",
    "# Dissolve counties to create state boundaries\n",
    "states = counties.dissolve(by='STATEFP').reset_index()\n",
    "states.to_crs('EPSG:5070', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd322bb-7b4d-438a-9dd2-0dc799ea224e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all available layers in the .gdb file\n",
    "layer_name = fiona.listlayers(gdb_path)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08eba5bc-d518-4747-8afb-681f635d6ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all available layers and their CRS information\n",
    "try:\n",
    "    with fiona.Env():\n",
    "        for layer in fiona.listlayers(gdb_path):\n",
    "            with fiona.open(gdb_path, layer=layer) as src:\n",
    "                print(f\"Layer: {layer}\")\n",
    "                print(f\"CRS: {src.crs}\")\n",
    "                print(f\"CRS WKT: {src.crs_wkt}\")\n",
    "                print('-' * 40)\n",
    "except Exception as e:\n",
    "    print(f\"Error accessing .gdb file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2143efc4-44c2-484a-94b2-1191e12c2d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create a dictionary of bounds\n",
    "def get_bounds_dict(geometry):\n",
    "    minx, miny, maxx, maxy = geometry.bounds\n",
    "    return {\n",
    "        'xmax': maxx+100,\n",
    "        'xmin': minx-100,\n",
    "        'ymax': maxy+100,\n",
    "        'ymin': miny-100\n",
    "    }\n",
    "\n",
    "# Create a dictionary of dictionaries\n",
    "bounds_dict = {row['STATEFP']: \n",
    "               get_bounds_dict(row.geometry) \n",
    "               for idx, row in states.iterrows()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279df8c9-b3f0-4151-82e6-dd03c82f9eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_crs(minx, miny, maxx, maxy, input_crs):\n",
    "    # Create Transformer objects\n",
    "    transformer = Transformer.from_crs(input_crs, src.crs, always_xy=True)\n",
    "\n",
    "    # Transform the bounding box to Albers Equal Area coordinates\n",
    "    xmin_albers, ymin_albers = transformer.transform(minx, miny)\n",
    "    xmax_albers, ymax_albers = transformer.transform(maxx, maxy)\n",
    "\n",
    "    # Define the projected bounding box\n",
    "    projected_bbox = (xmin_albers, ymin_albers, xmax_albers, ymax_albers)\n",
    "    return projected_bbox"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a85ea0c-f143-4b22-b45d-5f26bdb7ec86",
   "metadata": {},
   "source": [
    "### 2. Transfer CSB to Raster Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98396150-0658-447a-a1dc-1d69841ba289",
   "metadata": {},
   "outputs": [],
   "source": [
    "geographic_bbox = bounds_dict[state_fips]\n",
    "projected_bbox = change_crs(geographic_bbox['xmin'], geographic_bbox['ymin'],\n",
    "                            geographic_bbox['xmax'], geographic_bbox['ymax'],\n",
    "                            states.crs)\n",
    "# Read the layer with the projected bounding box filter\n",
    "CSB = gpd.read_file(gdb_path, layer=layer_name, bbox=projected_bbox)\n",
    "CSB = CSB.to_crs('EPSG:26915')\n",
    "CSB = CSB.drop(columns=['CSBID', 'CSBYEARS', 'CSBACRES', 'STATEFIPS', 'STATEASD', \n",
    "                              'ASD', 'CNTY', 'CNTYFIPS', 'INSIDE_X', 'INSIDE_Y',\n",
    "                              'Shape_Length', 'Shape_Area'])\n",
    "CSB.to_file(os.path.join(output_dir, f'CSB_{state_abb}.shp'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf83da09-3ac6-4b2f-b195-1509ee04bf71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the output raster properties\n",
    "output_crs = CSB.crs  # Use the same CRS as the GeoDataFrame\n",
    "resolution = 30  # Define the desired resolution in map units (e.g., meters)\n",
    "cols = CSB.columns.drop('geometry')  # Columns to rasterize\n",
    "\n",
    "# Calculate the bounds of the raster from the bounds of the GeoDataFrame\n",
    "minx, miny, maxx, maxy = CSB.total_bounds\n",
    "width = int((maxx - minx) / resolution)\n",
    "height = int((maxy - miny) / resolution)\n",
    "\n",
    "# Define the transform for the raster (affine transformation matrix)\n",
    "transform = from_origin(minx, maxy, resolution, resolution)\n",
    "\n",
    "# Function to rasterize a single column\n",
    "def rasterize_column(gdf, column_name):\n",
    "    shapes = ((geom, value) for geom, value in zip(gdf.geometry, gdf[column_name]))\n",
    "    raster = rasterize(\n",
    "        shapes,\n",
    "        out_shape=(height, width),\n",
    "        transform=transform,\n",
    "        fill=np.nan,  # Value to use for areas outside of the geometries\n",
    "        dtype='float32'  # Change dtype as needed\n",
    "    )\n",
    "    return raster\n",
    "\n",
    "for column in cols:\n",
    "    raster_data = rasterize_column(CSB, column)\n",
    "    \n",
    "    # Define the output filename and path\n",
    "    output_filename = f\"{state_abb}_{column}.tif\"\n",
    "    output_path = os.path.join(output_dir, output_filename)\n",
    "    \n",
    "    # Write the raster to a file\n",
    "    with rasterio.open(\n",
    "        output_path,\n",
    "        'w',\n",
    "        driver='GTiff',\n",
    "        height=height,\n",
    "        width=width,\n",
    "        count=1,  # Number of bands\n",
    "        dtype=raster_data.dtype,\n",
    "        crs=output_crs,\n",
    "        transform=transform,\n",
    "    ) as dst:\n",
    "        dst.write(raster_data, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5827c1-1b0b-4aae-811c-f2e106fc664a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the output raster properties\n",
    "output_crs = CSB.crs  # Use the same CRS as the GeoDataFrame\n",
    "resolution = 30  # Define the desired resolution in map units (e.g., meters)\n",
    "cols = CSB.columns.drop('geometry')  # Columns to rasterize\n",
    "\n",
    "# Calculate the bounds of the raster from the bounds of the GeoDataFrame\n",
    "minx, miny, maxx, maxy = CSB.total_bounds\n",
    "width = int((maxx - minx) / resolution)\n",
    "height = int((maxy - miny) / resolution)\n",
    "\n",
    "# Define the transform for the raster (affine transformation matrix)\n",
    "transform = from_origin(minx, maxy, resolution, resolution)\n",
    "\n",
    "# Function to rasterize a single column\n",
    "def rasterize_column(gdf, column_name):\n",
    "    shapes = ((geom, value) for geom, value in zip(gdf.geometry, gdf[column_name]))\n",
    "    raster = rasterize(\n",
    "        shapes,\n",
    "        out_shape=(height, width),\n",
    "        transform=transform,\n",
    "        fill=np.nan,  # Value to use for areas outside of the geometries\n",
    "        dtype='float32'  # Change dtype as needed\n",
    "    )\n",
    "    return raster\n",
    "\n",
    "for column in cols:\n",
    "    raster_data = rasterize_column(CSB, column)\n",
    "    \n",
    "    # Define the output filename and path\n",
    "    output_filename = f\"{state_abb}_{column}.tif\"\n",
    "    output_path = os.path.join(output_dir, output_filename)\n",
    "    \n",
    "    # Write the raster to a file\n",
    "    with rasterio.open(\n",
    "        output_path,\n",
    "        'w',\n",
    "        driver='GTiff',\n",
    "        height=height,\n",
    "        width=width,\n",
    "        count=1,  # Number of bands\n",
    "        dtype=raster_data.dtype,\n",
    "        crs=output_crs,\n",
    "        transform=transform,\n",
    "    ) as dst:\n",
    "        dst.write(raster_data, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1717db-9e30-4958-b903-ead02df9b8fc",
   "metadata": {},
   "source": [
    "### 3. Read in CLU Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d080961a-52fe-493a-85b4-8476de3167df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate a random point within a polygon\n",
    "def random_point_in_polygon(polygon):\n",
    "    minx, miny, maxx, maxy = polygon.bounds\n",
    "    while True:\n",
    "        p = Point(np.random.uniform(minx, maxx), np.random.uniform(miny, maxy))\n",
    "        if polygon.contains(p):\n",
    "            return p\n",
    "\n",
    "# Function to extract value at points in gdf_points from a raster\n",
    "def extract_raster_values(gdf_points, year):\n",
    "    # Path to the GeoTIFF file\n",
    "    raster_path = os.path.join(rf'Data_cleaned\\CLU_{state_abb}', f'{state_abb}_CDL{year}.tif')\n",
    "    \n",
    "    # Extract raster values at each point\n",
    "    raster_values = []\n",
    "    \n",
    "    with rasterio.open(raster_path) as src:\n",
    "        raster_crs = src.crs  # Get the CRS of the raster\n",
    "        # Check if the CRS of the points matches the raster CRS\n",
    "        if gdf_points.crs != raster_crs:\n",
    "            # Reproject the points to the raster CRS if they do not match\n",
    "            gdf_points = gdf_points.to_crs(raster_crs)\n",
    "        \n",
    "        for point in gdf_points.geometry:\n",
    "            if point is None:\n",
    "                raster_values.append(None)\n",
    "            else:\n",
    "                # Get the raster value at the point\n",
    "                coords = [(point.x, point.y)]\n",
    "                value = list(src.sample(coords))[0][0]\n",
    "                raster_values.append(value)\n",
    "    \n",
    "    # Add the raster values to the points GeoDataFrame\n",
    "    gdf_points[f'CDL{year}'] = raster_values\n",
    "    return gdf_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba580b30-ec46-44c9-83c6-c51c4fea17e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Start timing\n",
    "start_time = time.time()\n",
    "\n",
    "# List to hold processed GeoDataFrames\n",
    "list_gdfs = []\n",
    "\n",
    "# Iterate through each folder in the original_directory\n",
    "for folder_name in os.listdir(CLU_directory):\n",
    "    print(folder_name)\n",
    "    folder_path = os.path.join(CLU_directory, folder_name)\n",
    "    if os.path.isdir(folder_path):\n",
    "        # Find the shapefile in the folder\n",
    "        for file_name in os.listdir(folder_path):\n",
    "            if file_name.endswith('.shp'):\n",
    "                # Read the shapefile into a GeoDataFrame\n",
    "                gdf = gpd.read_file(os.path.join(folder_path, file_name))\n",
    "                # Apply negative buffer\n",
    "                gdf['geometry'] = gdf['geometry'].buffer(-neg_buffer)\n",
    "                # Calculate the area for each geometry\n",
    "                gdf['area'] = gdf.geometry.area/4046.85642\n",
    "                # Filter rows based on acreage\n",
    "                gdf = gdf[gdf['area'] >= threshold_acreage]\n",
    "                gdf = gdf.reset_index(names='ID')\n",
    "                # Calculate the inside point for each geometry\n",
    "                inside_points = []\n",
    "                for geom in gdf.geometry:\n",
    "                    # Check if the geometry is a valid polygon\n",
    "                    if geom.is_empty:\n",
    "                        inside_points.append(None)  # Handle non-polygon geometries or empty geometries\n",
    "                        continue\n",
    "                    \n",
    "                    # Calculate the centroid\n",
    "                    centroid = geom.centroid\n",
    "                    \n",
    "                    # Check if the centroid is inside the geometry\n",
    "                    if geom.contains(centroid):\n",
    "                        inside_points.append(centroid)\n",
    "                    else:\n",
    "                        # Generate a random point inside the geometry\n",
    "                        random_point = random_point_in_polygon(geom)\n",
    "                        inside_points.append(random_point)\n",
    "                \n",
    "                gdf_points = gdf.copy()\n",
    "                gdf_points.geometry = inside_points\n",
    "                gdf_points = gdf_points.dropna()\n",
    "    \n",
    "                for year in range(2013, 2024):\n",
    "                    gdf_points = extract_raster_values(gdf_points, year)\n",
    "    \n",
    "                gdf_points = gdf_points[['ID','CDL2013', 'CDL2014', 'CDL2015', 'CDL2016', \n",
    "                                         'CDL2017', 'CDL2018', 'CDL2019', 'CDL2020', \n",
    "                                         'CDL2021', 'CDL2022', 'CDL2023']].dropna(thresh=4)\n",
    "                gdf = gdf.merge(gdf_points, on=['ID'], how='inner')\n",
    "                list_gdfs.append(gdf)\n",
    "            \n",
    "# End timing\n",
    "end_time = time.time()\n",
    "# Calculate elapsed time\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Elapsed time: {elapsed_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f31e832-c108-4ca1-9ff1-f2601112b8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "Uni_CRS = list_gdfs[0].crs\n",
    "for i in list_gdfs:\n",
    "    if i.crs != Uni_CRS:\n",
    "        i.to_crs(Uni_CRS, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132d536a-5624-4dcb-a6bb-9fe5f900fece",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLU = pd.concat(list_gdfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b5e12c-ebf9-49e8-8c39-276f0dd57140",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLU.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111dedf5-44de-423c-89f1-b5653e976bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLU.reset_index(inplace=True)\n",
    "CLU.drop(columns=['ID', 'index'], inplace=True)\n",
    "CLU.reset_index(inplace=True, names=['ID'])\n",
    "CLU['ID'] = [f'{state_abb}{str(x).zfill(8)}' for x in CLU['ID']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9aec51-3965-4401-9395-80cb0d28a6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLU[['ID', 'geometry']].to_file(os.path.join(output_dir, f'CLU_{state_abb}.shp'))\n",
    "CLU.drop(columns=['geometry']).to_csv(os.path.join(output_dir, f'CLU_{state_abb}.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
